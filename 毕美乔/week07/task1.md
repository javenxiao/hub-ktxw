# 03_DeepWalk 与 word2vec 的关系：

DeepWalk 设计为 “随机游走 + Word2Vec”。

也就是说：

- **Word2Vec** 原本是自然语言处理（NLP）中学习“词向量”的模型；
- **DeepWalk** 把这个思想迁移到了图上，学习“节点向量”；
- 所以 **Word2Vec 是 DeepWalk 的核心训练机制**，只是输入从“句子中的词”变成了“随机游走序列中的节点”。


## 具体流程：

对每个节点 𝑣_i v_i，执行多次随机游走（random walk），得到一系列节点序列（如：A → B → C → D → E）。

把这些序列当成“句子”，节点当成“单词”。 使用 Word2Vec（Skip-gram 模型）去学习每个节点的 embedding。

## 优点：

充分利用随机游走捕获结构信息；

结合自然语言处理的思想（Word2Vec）；

简单高效。

## 缺点：

仅依赖随机游走，无法控制局部/全局结构的平衡；

无法直接结合节点特征。
